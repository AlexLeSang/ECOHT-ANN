\documentclass[a4paper,12pt]{article}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
%\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{multicol}
\usepackage{geometry}
\usepackage[pdftex]{graphicx}
\usepackage{hyperref}
\usepackage{indentfirst}
\hypersetup{colorlinks=true}
%\renewcommand{\baselinestretch}{1.5}
%\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\geometry{hmargin={20mm,20mm},vmargin={20mm,20mm}}
%opening
\setcounter{tocdepth}{3} 
\begin{document}
\large
%\maketitle
\begin{titlepage}
 \begin{center}
Warsaw University of Technology\\
The Faculty of Electronics and Information Technology
  
  \vspace{35ex}
  
Contemporary Heuristic Techniques  course project\\
subject:\\
''Application of the Artificial neural networks in the approximation task''

  
  \vspace{35ex}
  
 \end{center}
 \begin{flushright}
Supervisor:\\
Piotr Bilski\\
Made by:\\
Oleksandr Halushko\\
Danylo Lizanets

\vspace{15ex}

 \end{flushright}
  
  \begin{center}
   Warsaw 2013
  \end{center}

\end{titlepage}

\tableofcontents
\newpage
\section{Subject}

Application of the artificial neural networks in the approximation task.

\section{Aim}

Apply the artificial neural network to approximate a two-dimensional function. Design the structure of the network and make it learn the selected number of the points being a part of the function, then test it against the new set of the points. Test different structures of the network. Examine the learning process of the designed network.

\section{Theory}
\subsection{Artificial neural networks}
\subsubsection{Definition}

Artificial neural network is a mathematical model of biological neural network. It consists of artificial neurons and processes information using a connectionist approach to computation. Neural networks are used for modeling complex relationships between inputs and outputs or searching of patterns in data.

\subsubsection{Types of artificial neural networks}

There are many different types of the artificial neural networks used for different purposes. They may be classified by such parameters as:
\begin{itemize}
 \item number of layers
  \begin{itemize}
   \item one layer
   \item two layers
   \item multilayer
  \end{itemize}
  \item number of information move directions
  \begin{itemize}
   \item one direction
   \item many directions
  \end{itemize}
  \item number of inputs
  \begin{itemize}
   \item single input 
   \item multiple input
  \end{itemize}
  \item existance of recursive feedback loops
  \item type of learning
  \begin{itemize}
   \item outside teaching
   \item self-teaching
  \end{itemize}

\end{itemize}


 %(one-, two-, multilayer),  directions(one, many), inputs (single, multiple), existance of recursive feedback loops and type of learning. 

The feed-forward neural network is the most simple type of artificial neural network. In this type network the information moves in only one direction â€” forwards: from the input nodes data goes through the hidden nodes and to the output nodes. There are no cycles or loops in the network.

\subsubsection{Training process}

Training a neural network model essentially means selecting one model from the set of allowed models that minimizes the cost criterion.

A commonly used cost is the mean-squared error, which tries to minimize the average squared error between the network's output, $f(x)$, and the target value y over all the example pairs. When one tries to minimize this cost using gradient descent for the class of neural networks called multilayer perceptrons, one obtains the common and well-known backpropagation algorithm for training neural networks.

There are three major learning paradigms, each corresponding to a particular abstract learning task. These are supervised learning, unsupervised learning and reinforcement learning.
Supervised learning

In \textbf{supervised learning}, we are given a set of example pairs $ (x, y), x \in X, y \in Y $ and the aim is to find a function $ f : X \rightarrow Y $ in the allowed class of functions that matches the examples. In other words, we wish to infer the mapping implied by the data; the cost function is related to the mismatch between our mapping and the data and it implicitly contains prior knowledge about the problem domain.

A commonly used cost is the mean-squared error, which tries to minimize the average squared error between the network's output, $f(x)$, and the target value y over all the example pairs. When one tries to minimize this cost using gradient descent for the class of neural networks called multilayer perceptrons, one obtains the common and well-known backpropagation algorithm for training neural networks.

Tasks that fall within the paradigm of supervised learning are pattern recognition (also known as classification) and regression (also known as function approximation). The supervised learning paradigm is also applicable to sequential data (e.g., for speech and gesture recognition). This can be thought of as learning with a "teacher," in the form of a function that provides continuous feedback on the quality of solutions obtained thus far.
Unsupervised learning

In \textbf{unsupervised learning}, some data $ x $ is given and the cost function to be minimized, that can be any function of the data $ x $ and the network's output, $f$

The cost function is dependent on the task (what we are trying to model) and our a priori assumptions (the implicit properties of our model, its parameters and the observed variables).

As a trivial example, consider the model $f(x) = a$, where $ a $ is a constant and the cost $ C=E[(x - f(x))^2] $. Minimizing this cost will give us a value of $ a $ that is equal to the mean of the data. The cost function can be much more complicated. Its form depends on the application: for example, in compression it could be related to the mutual information between $ x $ and $ f(x) $, whereas in statistical modeling, it could be related to the posterior probability of the model given the data. (Note that in both of those examples those quantities would be maximized rather than minimized).

Tasks that fall within the paradigm of unsupervised learning are in general estimation problems; the applications include clustering, the estimation of statistical distributions, compression and filtering.
Reinforcement learning

In \textbf{reinforcement learning}, data $ x $ are usually not given, but generated by an agent's interactions with the environment. At each point in time $ t $, the agent performs an action $ y_t  $ and the environment generates an observation $ x_t $ and an instantaneous cost $ c_t $, according to some (usually unknown) dynamics. The aim is to discover a policy for selecting actions that minimizes some measure of a long-term cost; i.e., the expected cumulative cost. The environment's dynamics and the long-term cost for each policy are usually unknown, but can be estimated.

More formally, the environment is modeled as a Markov decision process (MDP) with states $ \{s_1,...,s_n\}\in S $ and actions $\{a_1,...,a_m\} \in A $ with the following probability distributions: the instantaneous cost distribution $ P(c_t|s_t) $, the observation distribution $ P(x_t|s_t) $ and the transition $ P(s_{t+1}|s_t, a_t), $ while a policy is defined as conditional distribution over actions given the observations. Taken together, the two define a Markov chain (MC). The aim is to discover the policy that minimizes the cost; i.e., the MC for which the cost is minimal.

Tasks that fall within the paradigm of reinforcement learning are control problems, games and other sequential decision making tasks.

\subsection{Approximation}
\subsubsection{What approximation is}

Function approximation, which finds the underlying relationship from a given finite input-output data is the fundamental problem in a vast majority of real world applications, such as prediction, pattern recognition, data mining and classification. Various methods have been developed to address this problem, where one of them is by using artificial neural networks.

\subsubsection{Artificial neural network using for function approximation}

Due to the universal approximation theorem, the standard multilayer feed-forward neural network with a single hidden layer, which contains finite number of hidden neurons, is a universal approximator for continuous functions on compact subsets of $R^n$.

Let $\varphi(\bullet) $ be a nonconstant, bounded, and monotonically-increasing continuous function. Let $I_m$ denote the m-dimensional unit hypercube $ [0,1]_m. $ The space of continuous functions on $ I_m $ is denoted by $C(I_m)$. Then, given any function $ f \in C(I_m) $ and $ \varepsilon > 0 $, there exist an integer $ N $ and real constants $ \alpha_i, b_i \in R, \omega_i \in Rm $, where $ i = 1, \hdots, N $ such that we may define:

\begin{equation}
 F(x) = \sum\limits_{i=1}^N\alpha_i\varphi(\omega_i^Tx+b_i) 
\end{equation}

as an approximate realization of the function $ f $ ; that is,

\begin{equation}
 |F(x)-f(x)|<\varepsilon
\end{equation}

for all $ x \in I_m$. In other words, function of the form $ F(x) $ are dence in $ C(I_m) $.   
\begin{figure}[ht]
 \centering
 \includegraphics[scale=0.4]{neurons.png}
 \caption{Neural network with one hidden layer}
\end{figure}

\subsection{Backpropagation}

Backpropagation, an abbreviation for "backward propagation of errors", is a common method of training artificial neural networks. From a desired output, the network learns from many inputs, similar to the way a child learns to identify a dog from examples of dogs.

It is a supervised learning method, and is a generalization of the delta rule. It requires a dataset of the desired output for many inputs, making up the training set. It is most useful for feed-forward networks (networks that have no feedback, or simply, that have no connections that loop). Backpropagation requires that the activation function used by the artificial neurons (or "nodes") be differentiable.

There are three modes of learning to choose from: on-line, batch and stochastic. In on-line and stochastic learning, each propagation is followed immediately by a weight update. In batch learning, many propagations occur before updating the weights. Batch learning requires more memory capacity, but on-line and stochastic learning require more updates. On-line learning is used for dynamic environments that provide a continuous stream of new patterns. Stochastic learning and batch learning both make use of a training set of static patterns. Stochastic goes through the data set in a random order in order to reduce its chances of getting stuck in local minima. Stochastic learning is also much faster than batch learning since weights are updated immediately after each propagation. Yet batch learning will yield a much more stable descent to a local minima since each update is performed based on all patterns.

\subsubsection{Propagation}
\begin{itemize}

 \item Phase 1: Propagation

Each propagation involves the following steps:

Forward propagation of a training pattern's input through the neural network in order to generate the propagation's output activations.

Backward propagation of the propagation's output activations through the neural network using the training pattern target in order to generate the deltas of all output and hidden neurons.

\item Phase 2: Weight update

For each weight-synapse follow the following steps:

Multiply its output delta and input activation to get the gradient of the weight.
    
Bring the weight in the opposite direction of the gradient by subtracting a ratio of it from the weight.

This ratio influences the speed and quality of learning; it is called the learning rate. The sign of the gradient of a weight indicates where the error is increasing, this is why the weight must be updated in the opposite direction.

Repeat phase 1 and 2 until the performance of the network is satisfactory.
\end{itemize}

\subsubsection{Limitations}

\begin{itemize}

 \item The result may converge to a local minimum. The "hill climbing" strategy of gradient descent is guaranteed to work if there is only one minimum. However, oftentimes the error surface has many local minimum and maximum. If the starting point of the gradient descent happens to be somewhere between a local maximum and local minimum, then going down the direction with the most negative gradient will lead to the local minimum.
    \item Gradient descent can find the local minimum instead of the global minimum
    \item The convergence obtained from backpropagation learning is very slow.
    \item The convergence in backpropagation learning is not guaranteed.
    \item Backpropagation learning does not require or normalization of input vectors; however, normalization could improve performance.[8]
\end{itemize}

\section{Domain description}

\subsection{Function}
Function for approximation we using in our project is ''Sombrero'' function which formula is such:
\begin{equation}
 t = \sqrt{((a+bx)^2+(a+by)^2)} \text{, where } a = -8, b = 16
 \end{equation}
 \begin{equation}
 z = \frac
 {\sin(t)}
 {t}
\end{equation}

The function is mapped on $[0,1]_2$ hypercube due to the requirements of universal approximation theorem.





\section{Program description}

\subsection{Program structure}

For testing and training neural networks was developed GUI application, which allows user to create neural networks, set different parameters of it and give it data sets for training and  testing to obtain appropriate results. The application consists of three parts: Neural Network, IO/Preparing data, GUI. 

\subsubsection{Classes}
\begin{itemize}
 \item Facade - connects all parts of the application together, receiving information and commands from other classes, and sends them to recipient;
 \begin{figure}[ht]
 \centering
 \includegraphics[scale=0.4]{facadecppincl.png}
 \caption{Facade class connections}
\end{figure}

 \begin{figure}[ht]
 \centering
 \includegraphics[scale=0.4]{facadehppincl.png}
 \caption{Facade class connections}
\end{figure}

\item Network - represents artificial neural network, gets paremeters of network and training/testing data samples, returns ...

 \begin{figure}[ht]
 \centering
 \includegraphics[scale=0.5]{networkcppincl.png}
 \caption{Network class connections}
\end{figure}

 \begin{figure}[ht]
 \centering
 \includegraphics[scale=0.5]{networkhppincl.png}
 \caption{Network class connections}
\end{figure}

\item Layer - represents an one layer of artificial neural network, gets parameters that define number of neurons in layer and number of inputs of single neuron.

\item Neuron - represents a single neuron of artificial neural network.

\item Preprocessor - reads and writes data to files, prepares data for further transmission to artificial neural network by splitting it to training and testing sets of input and output parameters.

 \begin{figure}[ht]
 \centering
 \includegraphics[scale=0.5]{preprocessorcppincl.png}
 \caption{Preprocessor class connections}
\end{figure}

\end{itemize}

\subsection{Program interface}
\begin{figure}[ht]
 \centering
 \includegraphics[scale=0.6]{interface.png}
 \caption{Application interface}
\end{figure}

\begin{figure}[ht]
 \centering
 \includegraphics[scale=0.6]{interface1.png}
 \caption{Graphical error representation}
\end{figure}

\end{document}


